{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srahul101082/DataMining/blob/master/Cart_Model_Bank_Date_Set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOmUsVD0arwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from pandas import DataFrame, Series\n",
        "from IPython.display import Image \n",
        "from io import StringIO\n",
        "import pydotplus\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxI_WIPWbCsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading and loading the datesets\n",
        "dev_dataset = pd.read_csv('/content/DEV_SAMPLE.csv',header=0)\n",
        "holdout_dataset=pd.read_csv('/content/HOLDOUT_SAMPLE.csv',header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAyYD-XObaxv",
        "colab_type": "text"
      },
      "source": [
        "**Let's analyze data**\n",
        "\n",
        "We can now take a closer look at our loaded data\n",
        "\n",
        "Let’s start off by confirming the dimensions of the datasets, e.g. the number of rows and columns.\n",
        "\n",
        "Let's first check the dev_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0DcCfMNbeEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dev_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUMU9M2QcIWr",
        "colab_type": "text"
      },
      "source": [
        "### We have 14000 rows of record and it has 10 attributes including the output attribute Target.\n",
        "\n",
        "Let's now check the holdout_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl3KLxH6bo_3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj5rKGRgbrAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(holdout_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eECa7REZcSmX",
        "colab_type": "text"
      },
      "source": [
        "### Here we have 6000 rows of record and it has 10 attributes including the output attribute Target.\n",
        "\n",
        "Let’s also look at the data types of each attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjL0dBktcOrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dev_dataset.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4dhiC1ceKL",
        "colab_type": "text"
      },
      "source": [
        "# **Summay of data**\n",
        "\n",
        "**Categorical Variables :**\n",
        "\n",
        "1. Cust_ID\n",
        "2. Gender\n",
        "3. Occupation\n",
        "4. AGE_BKT\n",
        "**Numerical Variables :**\n",
        "\n",
        "1. Target\n",
        "2. Age\n",
        "3. No_OF_CR_TXNS\n",
        "4. SCR\n",
        "5. Holding_Period\n",
        "6. Balance\n",
        "\n",
        "**\"Target\" is our dependent variable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6x0Od3_cziT",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning and Data Preparations\n",
        "Dropping the attribute 'Cust_ID' as it does contain any importance in model building."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHS8lFjMcv-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_dataset.drop('Cust_ID', axis = 1,inplace=True)\n",
        "holdout_dataset.drop('Cust_ID', axis = 1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTv2elNmc7iU",
        "colab_type": "text"
      },
      "source": [
        "**Creating dummy variables for all categorical variables in both dataframes \"holdout_dataset\" and \"dev_dataset\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIuHs50Sc34g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_dev_dataset = pd.get_dummies(data=dev_dataset, columns = ['Gender','Occupation','AGE_BKT'] )\n",
        "dummy_holdout_dataset = pd.get_dummies(data=holdout_dataset, columns = ['Gender','Occupation','AGE_BKT'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2BjYE7GdC0c",
        "colab_type": "text"
      },
      "source": [
        "### **Let's see how it looks with dummy variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVT2nq5bc_xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_dev_dataset.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAghA7kwdiZ6",
        "colab_type": "text"
      },
      "source": [
        "Let's check if the dev data set contains any null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibOKKe0djXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_dev_dataset[dummy_dev_dataset.isnull().any(axis=1)].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq77R95fdplk",
        "colab_type": "text"
      },
      "source": [
        "### Let's now split dummy_dev_dataset in test and train. We will split the test and train data into 70:30 ration of train and test respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_3sBAvIdlEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will use the data frame where we had created dummy variables\n",
        "yDev = dummy_dev_dataset['Target'].values\n",
        "XDev = dummy_dev_dataset.drop(columns = ['Target'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(XDev, yDev, test_size=0.3, random_state=111)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAons61UdwXu",
        "colab_type": "text"
      },
      "source": [
        "Let's prepare our Holdout data set for final model validations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcQ7G_hIdtJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yHoldOut = dummy_holdout_dataset['Target'].values\n",
        "XHoldOut = dummy_holdout_dataset.drop(columns = ['Target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8obnxpo7dzaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = KFold(n_splits=10, random_state=1)\n",
        "model2=tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
        "result = model2.fit(X_train, y_train)\n",
        "results = cross_val_score(model2, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "accuracy_train2=np.sum(model2.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test2=np.sum(model2.predict(X_test)==y_test)/float(y_test.size)\n",
        "print(\"Accuracy on train data at depth=2 :-\",accuracy_train2)\n",
        "print(\"Accuracy on test data at depth=2 :-\",accuracy_test2)\n",
        "print(\"Mean Accuracy on test data at depth 2 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx--KDxLd2Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = KFold(n_splits=10, random_state=1)\n",
        "model3=tree.DecisionTreeClassifier(random_state=1, max_depth=3)\n",
        "result = model3.fit(X_train, y_train)\n",
        "results = cross_val_score(model3, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "accuracy_train3=np.sum(model3.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test3=np.sum(model3.predict(X_test)==y_test)/float(y_test.size)\n",
        "print(\"Accuracy on train data at depth=3 :-\",accuracy_train3)\n",
        "print(\"Accuracy on test data at depth=3 :-\",accuracy_test3)\n",
        "print(\"Mean Accuracy on test data at depth 3 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7XylcCqd46P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = KFold(n_splits=10, random_state=1)\n",
        "model4=tree.DecisionTreeClassifier(random_state=1, max_depth=4)\n",
        "result = model4.fit(X_train, y_train)\n",
        "results = cross_val_score(model4, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "accuracy_train4=np.sum(model4.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test4=np.sum(model4.predict(X_test)==y_test)/float(y_test.size)\n",
        "print(\"Accuracy on train data at depth=4 :-\",accuracy_train4)\n",
        "print(\"Accuracy on test data at depth=4 :-\",accuracy_test4)\n",
        "print(\"Mean Accuracy on test data at depth 4 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8mc6dKAd9jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5=tree.DecisionTreeClassifier(random_state=1, max_depth=5)\n",
        "result = model5.fit(X_train, y_train)\n",
        "results = cross_val_score(model5, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "accuracy_train5=np.sum(model5.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test5=np.sum(model5.predict(X_test)==y_test)/float(y_test.size)\n",
        "print(\"Accuracy on train data at depth=5 :-\",accuracy_train5)\n",
        "print(\"Accuracy on test data at depth=5 :-\",accuracy_test5)\n",
        "print(\"Mean Accuracy on test data at depth 5 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnju8W1deAVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6=tree.DecisionTreeClassifier(random_state=1, max_depth=6)\n",
        "result = model6.fit(X_train, y_train)\n",
        "results = cross_val_score(model6, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "accuracy_train6=np.sum(model6.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test6=np.sum(model6.predict(X_test)==y_test)/float(y_test.size)\n",
        "print(\"Accuracy on train data at depth=6 :-\",accuracy_train6)\n",
        "print(\"Accuracy on test data at depth=6 :-\",accuracy_test6)\n",
        "print(\"Mean Accuracy on test data at depth 6 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOmDxz7ceEvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model7=tree.DecisionTreeClassifier(random_state=1, max_depth=7)\n",
        "result = model7.fit(X_train, y_train)\n",
        "accuracy_train7=np.sum(model7.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test7=np.sum(model7.predict(X_test)==y_test)/float(y_test.size)\n",
        "results = cross_val_score(model7, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "print(\"Accuracy on train data at depth=7 :-\",accuracy_train7)\n",
        "print(\"Accuracy on test data at depth=7 :-\",accuracy_test7)\n",
        "print(\"Mean Accuracy on test data at depth 7 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWsH1m-AeG7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model8=tree.DecisionTreeClassifier(random_state=1, max_depth=8)\n",
        "result = model8.fit(X_train, y_train)\n",
        "accuracy_train8=np.sum(model8.predict(X_train)==y_train)/float(y_train.size)\n",
        "accuracy_test8=np.sum(model8.predict(X_test)==y_test)/float(y_test.size)\n",
        "results = cross_val_score(model8, X_train, y_train, cv=kfold,scoring='accuracy')\n",
        "\n",
        "print(\"Accuracy on train data at depth=8 :-\",accuracy_train8)\n",
        "print(\"Accuracy on test data at depth=8 :-\",accuracy_test8)\n",
        "print(\"Mean Accuracy on test data at depth 8 with Kfold splits=10 :-\",results.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTkPwjFOeLXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
        "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
        "print('{:1} {:>25} {:>20}'.format(2, accuracy_train2, accuracy_test2))\n",
        "print('{:1} {:>25} {:>20}'.format(3, accuracy_train3, accuracy_test3))\n",
        "print('{:1} {:>25} {:>20}'.format(4, accuracy_train4, accuracy_test4))\n",
        "print('{:1} {:>25} {:>20}'.format(5, accuracy_train5, accuracy_test5))\n",
        "print('{:1} {:>25} {:>20}'.format(6, accuracy_train6, accuracy_test6))\n",
        "print('{:1} {:>25} {:>20}'.format(7, accuracy_train7, accuracy_test7))\n",
        "print('{:1} {:>25} {:>20}'.format(8, accuracy_train8, accuracy_test8))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06KX0MaOeTM1",
        "colab_type": "text"
      },
      "source": [
        "It could be seen that, higher the depth, training score increases and matches perfects with the training data set. However higher the depth the tree goes, it overfit to the training data set. So it's no use keep increasing the tree depth. According to above observations, tree with a depth of 5 seems more reasonable as both training and test scores are reasonably high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyoQTvgweTRB",
        "colab_type": "text"
      },
      "source": [
        "**Based on above conclusive facts we could see that the model perfroms great at tree depth of 5 on dev_dataset with Training and Testing score being at par**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44jweBbweTUt",
        "colab_type": "text"
      },
      "source": [
        "**Let's validate model performence on holdout dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btvOdcN4eOBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultHoldOut = np.sum(model5.predict(XHoldOut)==yHoldOut)/float(yHoldOut.size)\n",
        "resultHoldOut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFccgim7erdy",
        "colab_type": "text"
      },
      "source": [
        "**As per our findings in above cell, our Model performence is even better on our Holdout data set. It exhibited the accuracy of \"0.917\" on holdout dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQWDsDVEe0qy",
        "colab_type": "text"
      },
      "source": [
        "## Let's find out the most important features in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ihvzGKex8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresList = (dummy_dev_dataset.drop('Target', axis=1)).columns.tolist()\n",
        "features = (dummy_dev_dataset.drop('Target', axis=1)).columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06cyaWye5DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Investigate most important features with depth =5\n",
        "\n",
        "fi = model5.feature_importances_\n",
        "\n",
        "l = len(features)\n",
        "for i in range(0,len(features)):\n",
        "    print('{:.<20} {:3}'.format(features[i],fi[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4XYwUMfCDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict probabilities\n",
        "probs = model5.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = probs[:, 1]\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(y_test, probs)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJejyhgWfI7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_decision_tree(model,feature_name,target_name):\n",
        "    dot_data = StringIO()  \n",
        "    tree.export_graphviz(model, out_file=dot_data,  \n",
        "                         feature_names=feature_name,  \n",
        "                         class_names=target_name,  \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True)  \n",
        "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "    return Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phOIqF1LfMxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "plot_decision_tree(model5, XHoldOut.columns, dummy_dev_dataset.columns[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krukY6l8fPGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}